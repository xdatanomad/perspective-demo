{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Prepare historical stock prices datasets for demo analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Media Stock Prices\n",
    "\n",
    "Major social media historical stock prices from 2012-2022 for meta, twitter, snap, pinterest, etsy.\n",
    "\n",
    "**Source**: [Kaggle: Major social media historical stock prices](https://www.kaggle.com/datasets/prasertk/social-media-stock-prices)\n",
    "\n",
    "Sample:\n",
    "```csv\n",
    "Date,Symbol,Adj Close,Close,High,Low,Open,Volume\n",
    "2012-05-18,FB,38.22999954223633,38.22999954223633,45.0,38.0,42.04999923706055,573576400.0\n",
    "2012-05-21,FB,34.029998779296875,34.029998779296875,36.65999984741211,33.0,36.529998779296875,168192700.0\n",
    "2012-05-22,FB,31.0,31.0,33.59000015258789,30.940000534057617,32.61000061035156,101786600.0\n",
    "2012-05-23,FB,32.0,32.0,32.5,31.360000610351562,31.3700008392334,73600000.0\n",
    "2012-05-24,FB,33.029998779296875,33.029998779296875,33.209999084472656,31.770000457763672,32.95000076293945,50237200.0\n",
    "2012-05-25,FB,31.90999984741211,31.90999984741211,32.95000076293945,31.110000610351562,32.900001525878906,37149800.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up Source Dataset\n",
    "\n",
    "Load and cleanup the original dataset:\n",
    "- Massage data types\n",
    "- Rename columns\n",
    "- Add additional metadata columns\n",
    "\n",
    "Save the result back to a new `csv` file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "\n",
    "\n",
    "# load social media stock prices data file\n",
    "orig_social_media_stock_prices = r\"./data/social_media_stocks_2012-2022.csv\"\n",
    "df = pd.read_csv(\n",
    "    orig_social_media_stock_prices,\n",
    "    header=0,\n",
    "    parse_dates=[0],\n",
    "    date_format='%Y-%m-%d',\n",
    "    on_bad_lines='skip',\n",
    ")\n",
    "\n",
    "# rename columns\n",
    "[df.rename(columns={col_name: str(col_name).lower().replace(' ', '_')}, inplace=True) for col_name in list(df.columns)]\n",
    "df.rename(columns={'symbol': 'ticker'}, inplace=True, errors='ignore')\n",
    "# optimize datatypes and columns for performance\n",
    "for col_name in ('adj_close', 'close', 'high', 'low', 'open'):\n",
    "    # df[col_name] = pd.to_numeric(df[col_name].map(lambda x: round(x, ndigits=6)), downcast='float')\n",
    "    df[col_name] = df[col_name].map(lambda x: round(x, ndigits=6))\n",
    "# downcast volume\n",
    "df['volume'] = pd.to_numeric(df['volume'], downcast='unsigned')\n",
    "# add a year column\n",
    "df.insert(1, 'year', pd.to_numeric(df['date'].map(lambda x: x.year), downcast='unsigned'))\n",
    "\n",
    "print(f\"df shape: {df.shape}\")\n",
    "# print(df.dtypes)\n",
    "display(df.sample(n=10))\n",
    "\n",
    "# save back to a csv file\n",
    "output_file = r\"./data/social_media_stocks_2012-2022.clean.csv\"\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot and visualize the original stock values over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Plotting the wave and amps using Plotly\n",
    "pio.templates.default = 'plotly_dark'\n",
    "fig = go.Figure()\n",
    "\n",
    "# iterate through tickers and graphs each with line charts\n",
    "tickers = list(df['ticker'].unique())\n",
    "for ticker in tickers:      \n",
    "    # Add the wave trace\n",
    "    xdf = df[df['ticker'] == ticker][['date', 'ticker', 'adj_close']]\n",
    "    fig.add_trace(go.Scatter(x=xdf['date'], y=xdf['adj_close'], mode='lines', name=ticker))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Portfolio\n",
    "\n",
    "This cell simulate a stock trading app portfolio:\n",
    "- Starts with a set amount of cash reserves in the bank\n",
    "- Trades stocks daily based on the ticker value\n",
    "- Adds daily trade columns: trade_price, trade_value, current_shares\n",
    "- Adjusts the total portfolio value and bank cash balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from utils import generate_varying_amplitude_wave\n",
    "\n",
    "# read the cleaned up file\n",
    "clean_stock_prices_filepath = r\"./data/social_media_stocks_2012-2022.clean.csv\"\n",
    "df = pd.read_csv(\n",
    "    clean_stock_prices_filepath,\n",
    "    header=0,\n",
    "    parse_dates=[0],\n",
    "    date_format='%Y-%m-%d',\n",
    "    on_bad_lines='skip',\n",
    ")\n",
    "\n",
    "print(f\"read source file. records: {len(df)}\")\n",
    "display(df.head())\n",
    "\n",
    "# Initialize starting parameters\n",
    "start_shares = {'FB': 100, 'TWTR': 200, 'PINS': 100, 'SNAP': 150, 'ETSY': 50}\n",
    "initial_cash_reserve = 50000.00  # Starting cash reserve for the portfolio\n",
    "scale = 1.0\n",
    "\n",
    "dfs = []\n",
    "# go through each ticker and \n",
    "#   - add a sinusoidal wave for the current_shares held in the portfolio\n",
    "#   - then add daily trades based on changes in current shares\n",
    "#   - add trade_prices, daily profit, and portfolio share amount\n",
    "for ticker in df['ticker'].unique():\n",
    "    xdf = df[df['ticker'] == ticker].copy().reset_index()\n",
    "    print(f\"ticker: {ticker} (len: {len(xdf)})\")\n",
    "    starting_shares = start_shares[ticker]\n",
    "    # generate a sinusoidal wave with peaks between 1.5-2.0x starting shares\n",
    "    wave = generate_varying_amplitude_wave(\n",
    "        length=len(xdf),\n",
    "        max_amp=int(starting_shares * (1 + np.random.uniform(0.5, 1, size=1)[0])), \n",
    "        frequency=2,\n",
    "        periods=3,\n",
    "    )\n",
    "    # shift the wave up by number of starting shares\n",
    "\n",
    "    current_shares = pd.Series(wave + starting_shares).map(lambda x: round(x, 4)) * scale\n",
    "    xdf['current_shares'] = current_shares\n",
    "    # apply daily trades\n",
    "    xdf['daily_trades'] = current_shares.diff().fillna(0).map(lambda x: round(x, 4))\n",
    "    # pick a random tarde value\n",
    "    xdf['trade_price'] = xdf.apply(lambda r: round(np.random.uniform(low=r['low'], high=r['high'], size=1)[0], ndigits=4), axis='columns')\n",
    "    # add daily tarde value in $$$\n",
    "    xdf['trade_value'] = -1 * round(xdf['daily_trades'] * xdf['trade_price'], ndigits=4)\n",
    "    dfs.append(xdf)\n",
    "\n",
    "# concatenate tickers dataframes together and sort\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df.sort_values(by=['date', 'ticker'], ignore_index=True)\n",
    "# display(df.sample(n=200))\n",
    "\n",
    "# calculating cash reserves and portfolio value\n",
    "current_portfolio_value = 0.0\n",
    "current_cash_reserve = initial_cash_reserve\n",
    "df['cash_reserves'] = initial_cash_reserve\n",
    "df['portfolio_value'] = 0.0\n",
    "cur_row = 0\n",
    "current_progress_percentage = 0\n",
    "portfolio = {}\n",
    "print(f\"Processing cash reserves & portfolio values\", end='')\n",
    "for i, row in df.iterrows():\n",
    "    df.at[i, 'cash_reserves'] = current_cash_reserve + row['trade_value']\n",
    "    portfolio[row['ticker']] = round(row['current_shares'] * row['adj_close'], ndigits=4)\n",
    "    # get total portfolio value\n",
    "    df.at[i, 'portfolio_value'] = round(sum(portfolio.values()), ndigits=4)\n",
    "    # calculate percentage\n",
    "    tmp_percentage = math.floor((i + 1) / len(df) * 10)\n",
    "    if current_progress_percentage != tmp_percentage:\n",
    "        print('.', end='', flush=True)\n",
    "        current_progress_percentage = tmp_percentage\n",
    "print()\n",
    "# round up cash reserves and portfolio values\n",
    "df['cash_reserves'] = df['cash_reserves'].map(lambda x: round(x, 2))\n",
    "df['portfolio_value'] = df['portfolio_value'].map(lambda x: round(x, 2))\n",
    "# drop index column\n",
    "df = df.drop(columns=['index'], errors='ignore')\n",
    "# output to file\n",
    "output_file = r\"./data/social_media_stocks_2012-2022.final.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Generation complete: \")\n",
    "display(df.sample(n=20))\n",
    "\n",
    "# print(\"\\nchecking null values:\")\n",
    "# df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize daily shares using plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Plotting the wave and amps using Plotly\n",
    "pio.templates.default = 'plotly_dark'\n",
    "fig = go.Figure()\n",
    "\n",
    "# iterate through tickers and graphs each with line charts\n",
    "tickers = list(df['ticker'].unique())\n",
    "for ticker in tickers:      \n",
    "    # Add the wave trace\n",
    "    xdf = df[df['ticker'] == ticker][['date', 'ticker', 'current_shares', 'adj_close']]\n",
    "    fig.add_trace(go.Scatter(x=xdf['date'], y=(xdf['current_shares'] * xdf['adj_close']), mode='lines', name=ticker))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig2 = go.Figure()\n",
    "# adding portfolio value\n",
    "fig2.add_trace(go.Scatter(x=df['date'], y=df['portfolio_value'], mode='lines', name='Portfolio Value'))\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox\n",
    "\n",
    "A sandbox for testing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df['ticker'].value_counts())\n",
    "\n",
    "# display(df[['year', 'ticker', 'volume']].groupby(['year', 'ticker']).agg(['count']))\n",
    "\n",
    "# display(df[df['year'].isin(list(range(2017, 2023)))]['ticker'].value_counts())\n",
    "# display(df[df['year'].isin(list(range(2017, 2023)))].shape)\n",
    "\n",
    "\n",
    "display(df['ticker'].unique())\n",
    "# display the first date where each ticker is being reported\n",
    "print(df[['ticker', 'date']].groupby('ticker').agg(['min']).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a short preview of the csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['year'] == 2020].head(n=50).to_csv(r\"./data/sample_social_media.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Historical Data File Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# List of top performing tech companies stock symbols\n",
    "TECH_SYMBOLS = [\n",
    "    \"AAPL\",   # Apple Inc.\n",
    "    \"MSFT\",   # Microsoft Corporation\n",
    "    \"GOOGL\",  # Alphabet Inc. (Class A)\n",
    "    \"GOOG\",   # Alphabet Inc. (Class C)\n",
    "    \"AMZN\",   # Amazon.com Inc.\n",
    "    \"FB\",     # Meta Platforms, Inc. (formerly Facebook)\n",
    "    \"NFLX\",   # Netflix, Inc.\n",
    "    \"NVDA\",   # NVIDIA Corporation\n",
    "    \"TSLA\",   # Tesla, Inc.\n",
    "    \"INTC\",   # Intel Corporation\n",
    "    \"CSCO\",   # Cisco Systems, Inc.\n",
    "    \"ADBE\",   # Adobe Inc.\n",
    "    \"ORCL\",   # Oracle Corporation\n",
    "    \"IBM\",    # International Business Machines Corporation\n",
    "    \"CRM\",    # Salesforce, Inc.\n",
    "    \"PYPL\",   # PayPal Holdings, Inc.\n",
    "    \"AMD\",    # Advanced Micro Devices, Inc.\n",
    "    \"TXN\",    # Texas Instruments Incorporated\n",
    "    \"QCOM\",   # Qualcomm Incorporated\n",
    "    \"AVGO\",   # Broadcom Inc.\n",
    "    \"SHOP\",   # Shopify Inc.\n",
    "    \"SNAP\",   # Snap Inc.\n",
    "    \"TWTR\",   # Twitter, Inc.\n",
    "    \"SQ\",     # Block, Inc. (formerly Square)\n",
    "    \"DOCU\"    # DocuSign, Inc.\n",
    "]\n",
    "\n",
    "data_file = r\"./data/historical_stock_prices.csv\"\n",
    "output_file = r\"data/historical_tech_stock_prices.csv\"\n",
    "\n",
    "# write the headers\n",
    "with open(output_file, mode='w') as outfile:\n",
    "    outfile.write(\"ticker,open,close,adj_close,low,high,volume,date\\n\")\n",
    "# load csv\n",
    "chunks = pd.read_csv(data_file, chunksize=10000)\n",
    "for df in chunks:\n",
    "    df = df[(df['ticker'].isin(TECH_SYMBOLS)) & (df['date'] >= '2012-01-01')]\n",
    "    # sort and output\n",
    "    df.to_csv(output_file, mode='a', index=False, header=False)\n",
    "# read back and sort by date and ticker\n",
    "df = pd.read_csv(output_file)\n",
    "df.sort_values(by=['date', 'ticker'], ignore_index=True, inplace=True)\n",
    "df.to_csv(output_file, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_file)\n",
    "print(f\"unique tickers: {len(df['ticker'].unique())} all: {len(TECH_SYMBOLS)}\")\n",
    "# not in\n",
    "print(f\"missing tickers: {[x for x in TECH_SYMBOLS if x not in df['ticker'].unique()]}\")\n",
    "# min max date\n",
    "df[['ticker', 'date']].groupby(by='ticker').agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Daily Stock Trades \n",
    "\n",
    "Based on the cleaned up tech historical prices (above), generate a series of daily trades performed by different brokers.\n",
    "\n",
    "- Stocks are traded in **logarithmic** daily distribution where some stocks are traded at higher quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate brokers\n",
    "broker_names = [\n",
    "    \"Slick Sam\", \"Trading Tina\", \"Money Mike\", \"Clever Cathy\", \"Profit Pete\", \n",
    "    \"Risky Rachel\", \"Big Bucks Bob\", \"Smart Susan\", \"Lucky Luke\"\n",
    "]\n",
    "brokers = broker_names\n",
    "# brokers = [f\"broker {i+1}: {name}\" for i, name in enumerate(broker_names)]\n",
    "\n",
    "# Parameters\n",
    "min_trades_per_day, max_trades_per_day = 50, 200\n",
    "share_prct_range = (0.00001, 0.0001)\n",
    "\n",
    "# Read historical stock price data\n",
    "data = pd.read_csv(\"data/historical_tech_stock_prices.csv\", parse_dates=['date'])\n",
    "\n",
    "# Create a list to hold generated trades\n",
    "trades = []\n",
    "\n",
    "# Get min and max dates from the data\n",
    "min_date = data['date'].min()\n",
    "max_date = data['date'].max()\n",
    "# max_date = data['date'].min() + timedelta(days=5)\n",
    "print(f\"generating between: {min_date} - {max_date}\")\n",
    "\n",
    "# Create a date range from min to max\n",
    "date_range = pd.date_range(start=min_date, end=max_date)\n",
    "\n",
    "# Traverse the data day by day\n",
    "for current_date in date_range:\n",
    "    # Filter data for the current day\n",
    "    day_data = data[data['date'] == current_date]\n",
    "    if day_data.empty:\n",
    "        continue\n",
    "    \n",
    "    # Sort tickers for this day and apply a smooth logarithmic curve to prioritize larger trades for certain tickers\n",
    "    num_tickers = len(day_data['ticker'].unique())\n",
    "    log_weights = np.logspace(0, -1, num=num_tickers)  # Smooth logarithmic distribution\n",
    "    day_data = day_data.assign(weight=log_weights)\n",
    "    day_data = day_data.sort_values(by='weight', ascending=False)\n",
    "    \n",
    "    # For each ticker in the current day, generate a series of trades\n",
    "    for _, row in day_data.iterrows():\n",
    "        # Get number of trades for the ticker on this day\n",
    "        num_trades = random.randint(min_trades_per_day, max_trades_per_day)\n",
    "        \n",
    "        # Generate trades for the ticker\n",
    "        for _ in range(num_trades):\n",
    "            # Random broker\n",
    "            broker = random.choice(brokers)\n",
    "            \n",
    "            # Random timestamps on the current date\n",
    "            trade_timestamp = current_date + timedelta(seconds=random.randint(0, 86399))\n",
    "            \n",
    "            # Bid and ask prices between high and low for the day\n",
    "            bid_price = np.random.uniform(row['low'], row['high'])\n",
    "            ask_price = np.random.uniform(row['low'], row['high'])\n",
    "            while ask_price <= bid_price:  # Ensure ask is higher than bid\n",
    "                ask_price = np.random.uniform(row['low'], row['high'])\n",
    "                \n",
    "            # Trade price between bid and ask\n",
    "            trade_price = np.random.uniform(bid_price, ask_price)\n",
    "            \n",
    "            # Bid-ask spread\n",
    "            bid_spread = ask_price - bid_price\n",
    "            \n",
    "            # Determine number of shares based on the logarithmic weight and the day's volume\n",
    "            shares = int(row['volume'] * row['weight'] * np.random.uniform(*share_prct_range))\n",
    "            \n",
    "            # Calculate trade value\n",
    "            trade_value = round(trade_price * shares, ndigits=6)\n",
    "            \n",
    "            # Create the trade record\n",
    "            trade = {\n",
    "                'trade_timestamp': trade_timestamp,\n",
    "                'ticker': row['ticker'],\n",
    "                'broker': broker,\n",
    "                'bid_price': round(bid_price, 4),\n",
    "                'ask_price': round(ask_price, 4),\n",
    "                'trade_price': round(trade_price, 4),\n",
    "                'bid_spread': round(bid_spread, 4),\n",
    "                'shares': shares,\n",
    "                'trade_value': round(trade_value, 4),\n",
    "                # meta columns\n",
    "                'open': round(row['open'], 6),\n",
    "                'close': round(row['adj_close'], 6),\n",
    "                'date': row['date'],\n",
    "            }\n",
    "            \n",
    "            # Include all the original stock data for the day\n",
    "            # for col in row.index:\n",
    "            #     trade[col] = row[col]\n",
    "            \n",
    "            # Append the trade record to the trades list\n",
    "            trades.append(trade)\n",
    "    # finished current date\n",
    "    print(f\"finished date: {current_date}\")\n",
    "\n",
    "# Convert the list of trades into a pandas DataFrame\n",
    "trades_df = pd.DataFrame(trades)\n",
    "# sort values\n",
    "# trades_df.sort_values(by=['trade_timestamp', 'ticker', 'broker'], ignore_index=True, inplace=True)\n",
    "\n",
    "# Output the generated trades DataFrame to a CSV file\n",
    "trades_df.to_csv(\"data/tech_trades.csv\", index=False)\n",
    "\n",
    "print(\"Trades simulation complete. Output saved to data/tech_trades.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# sort trades by timestamp and write back\n",
    "df = pd.read_csv(\"data/tech_trades.csv\")\n",
    "df.sort_values(by=['trade_timestamp', 'ticker', 'broker'], ignore_index=True, inplace=True)\n",
    "# reindex\n",
    "df.drop(columns=['trade_id'], inplace=True, errors='ignore')\n",
    "df.insert(0, 'trade_id', df.index + 100000)\n",
    "df.to_csv(\"data/tech_trades.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rewrite the entire final data file\n",
    "    - remove teh \"Broker #: \"\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# sort trades by timestamp and write back\n",
    "df = pd.read_csv(\"data/tech_trades.csv\", nrows=10)\n",
    "df['broker'] = df['broker'].map(lambda x: str(x).split(': ')[1])\n",
    "df.to_csv(\"data/tech_trades.csv\", index=False)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sort trades by timestamp and write back\n",
    "df = pd.read_csv(\"data/tech_trades.csv\", nrows=10000)\n",
    "schema = {\n",
    "    k: 'string' if str(v) == 'O' else \\\n",
    "       'string' if str(v) == 'object' else \\\n",
    "       'float' if str(v) == 'float64' else \\\n",
    "       'integer' if str(v) == 'int64' else \\\n",
    "       str(v)\n",
    "    for k, v in dict(df.dtypes).items()\n",
    "}\n",
    "\n",
    "print(schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
